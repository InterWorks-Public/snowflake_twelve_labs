{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ab3d0d-8bca-422e-ace6-ae19aded5148",
   "metadata": {
    "collapsed": false,
    "name": "Overview",
    "resultHeight": 306
   },
   "source": [
    "# AI Video Search with Snowflake and Twelve Labs\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook demonstrates how to build an end‑to‑end AI video search workflow using Snowflake, Twelve Labs, and Streamlit.  \n",
    "It covers creating video embeddings, storing and querying them in Snowflake, and surfacing results in an interactive UI.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "- Snowflake for data storage, vector search, and orchestration.\n",
    "- Twelve Labs for multimodal video and text embeddings.\n",
    "- Streamlit for an interactive, browser‑based search experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f044f0",
   "metadata": {},
   "source": [
    "## Environment configuration\n",
    "\n",
    "The following cells configure the notebook environment for running the AI video search demo:\n",
    "\n",
    "- Install Python dependencies required for Twelve Labs, video processing (`moviepy`, `ffmpeg`), and the Streamlit UI.\n",
    "- Set core configuration parameters such as the Twelve Labs API key placeholder, chosen model, Snowflake database and schema names.\n",
    "- Define the base table names used to store video segment embeddings, text query embeddings, video source URLs, and frame‑level results.\n",
    "- Configure stage names and fully qualified identifiers that determine where packages, UDFs, and extracted video frames are stored in Snowflake.\n",
    "\n",
    "Update these configuration values to match your own Snowflake account and Twelve Labs setup before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781ab29-3ff1-4772-b85e-d34a7e7243a1",
   "metadata": {
    "language": "sql",
    "name": "Secrets"
   },
   "outputs": [],
   "source": [
    "USE ROLE ACCOUNTADMIN;\n",
    "\n",
    "USE DATABASE MY_DB;\n",
    "USE SCHEMA MY_SCHEMA;\n",
    "CREATE OR REPLACE SECRET twelve_labs_api\n",
    " TYPE = GENERIC_STRING\n",
    " SECRET_STRING = 'YOUR_TWELVE_LABS_API_KEY';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff4894-a734-48e0-aee4-7474607cd615",
   "metadata": {
    "language": "sql",
    "name": "VIDEO_CONTAINER_RUNTIME_ROLE"
   },
   "outputs": [],
   "source": [
    "use role VIDEO_CONTAINER_RUNTIME_ROLE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a1346-927e-4c06-ae2a-d64492963295",
   "metadata": {
    "language": "python",
    "name": "Env_dependency_setup"
   },
   "outputs": [],
   "source": [
    "!pip install twelvelabs moviepy\n",
    "!DEBIAN_FRONTEND=noninteractive apt-get install -y ffmpeg\n",
    "\n",
    "# Note: The Twelve Labs SDK is provided as a ZIP in a Snowflake stage and loaded further down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4eb95-7d72-45b3-9515-21099df1f022",
   "metadata": {
    "language": "python",
    "name": "Parameters"
   },
   "outputs": [],
   "source": [
    "# TwelveLabs API key\n",
    "TWELVE_LABS_API_KEY = \"YOUR_TWELVE_LABS_API_KEY\"\n",
    "\n",
    "# TwelveLabs Model\n",
    "CHOSEN_MODEL = \"Marengo-retrieval-2.7\"\n",
    "\n",
    "# Env\n",
    "DB_NAME = \"MY_DB\"\n",
    "SCHEMA_NAME = \"MY_SCHEMA\"\n",
    "\n",
    "# Core tables\n",
    "VIDEO_SEGMENT_EMBEDDINGS_TABLE   = \"VIDEO_SEGMENT_EMBEDDINGS\"\n",
    "TEXT_QUERY_EMBEDDINGS_TABLE      = \"TEXT_QUERY_EMBEDDINGS\"\n",
    "VIDEO_SOURCE_URLS_TABLE          = \"VIDEO_SOURCE_URLS\"\n",
    "VIDEO_FRAME_RESULTS_TABLE        = \"VIDEO_FRAME_RESULTS\"\n",
    "\n",
    "# Stage names \n",
    "PKG_STAGE_NAME  = \"TRAFFIC_PACKAGES\"\n",
    "UDFS_STAGE_NAME = \"TRAFFIC_UDFS\"\n",
    "VIDEO_FRAME_STAGE_NAME     = \"STAGE_VIDEO_FRAMES\"\n",
    "\n",
    "# Fully qualified identifiers\n",
    "PKG_STAGE_FQN  = f'\"{DB_NAME}\".\"{SCHEMA_NAME}\".\"{PKG_STAGE_NAME}\"'\n",
    "UDFS_STAGE_FQN = f\"{DB_NAME}.{SCHEMA_NAME}.{UDFS_STAGE_NAME}\"\n",
    "VIDEO_FRAME_STAGE_FQN     = f\"{DB_NAME}.{SCHEMA_NAME}.{VIDEO_FRAME_STAGE_NAME}\"\n",
    "\n",
    "TEXT_QUERY_EMBEDDINGS_TABLE_FQN      = f\"{DB_NAME}.{SCHEMA_NAME}.{TEXT_QUERY_EMBEDDINGS_TABLE}\"\n",
    "VIDEO_SOURCE_URLS_TABLE_FQN          = f'\"{DB_NAME}\".\"{SCHEMA_NAME}\".\"{VIDEO_SOURCE_URLS_TABLE}\"'\n",
    "VIDEO_FRAME_RESULTS_TABLE_FQN        = f\"{DB_NAME}.{SCHEMA_NAME}.{VIDEO_FRAME_RESULTS_TABLE}\"\n",
    "VIDEO_SEGMENT_EMBEDDINGS_TABLE_FQN = f\"{DB_NAME}.{SCHEMA_NAME}.{VIDEO_SEGMENT_EMBEDDINGS_TABLE}\"\n",
    "\n",
    "\n",
    "# Classification categories - Update as required\n",
    "ZERO_SHOT_CATEGORIES = [\n",
    "    \"articulated semi-trailer\",\n",
    "    \"rigid box truck\",\n",
    "    \"tanker truck\",\n",
    "    \"flatbed truck\",\n",
    "    \"tipper dump truck\",\n",
    "    \"car carrier truck\",\n",
    "    \"refrigerated truck\",\n",
    "    \"concrete mixer truck\",\n",
    "    \"sand tipper truck\",\n",
    "    \"delivery van\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb351ea",
   "metadata": {},
   "source": [
    "## Environment and library setup\n",
    "\n",
    "This section imports all required Python libraries and initializes the Snowflake session and Twelve Labs client.\n",
    "\n",
    "- `twelvelabs` SDK for creating video and text embeddings.\n",
    "- `snowflake.snowpark` and `snowflake.cortex` for running queries and LLM calls inside Snowflake.\n",
    "- `requests`, `tempfile`, `os`, and `io` for downloading and handling video files.\n",
    "- `pandas` and `streamlit` for data manipulation and building the interactive UI.\n",
    "- `PIL` and `moviepy` for extracting and working with video frames.\n",
    "\n",
    "The call to `get_active_session()` retrieves the current Snowflake Snowpark session for this notebook, and `TwelveLabs(api_key=TWELVE_LABS_API_KEY)` constructs a client to interact with the Twelve Labs API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392068cc-ac1d-4aea-b511-a37eb563534c",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Import_Libraries",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "from twelvelabs import TwelveLabs\n",
    "from twelvelabs.models.embed import EmbeddingsTask\n",
    "from twelvelabs.models.task import Task\n",
    "\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake import cortex\n",
    "import snowflake\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "import tempfile\n",
    "import contextlib\n",
    "\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from PIL import Image as PILImage\n",
    "from moviepy import VideoFileClip\n",
    "\n",
    "session = get_active_session()\n",
    "twelvelabs_client = TwelveLabs(api_key=TWELVE_LABS_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c8c772",
   "metadata": {},
   "source": [
    "## Core helper functions\n",
    "\n",
    "The next cells define helper functions that encapsulate the main steps of the video search workflow:\n",
    "\n",
    "- `create_video_embeddings` is a Snowflake UDTF that calls Twelve Labs to generate and return segment‑level video embeddings for a given video URL.\n",
    "- `create_and_store_text_query_embedding(...)` creates a text embedding for a query using Twelve Labs and stores it in Snowflake.\n",
    "- `zero_shot_classify_sql(...)` uses Snowflake AI to classify a query into one of several vehicle or scene categories.\n",
    "- `semantic_search(...)` runs a similarity search over precomputed video segment embeddings to find relevant segments for a query.\n",
    "- `apply_llm_scoring_to_frames(...)` applies an LLM‑based scoring step to refine how well individual frames match the user’s query.\n",
    "- `generate_video_embed(...)` creates and persists video segment embeddings for a given video URL if they do not already exist.\n",
    "- `store_query_results_to_table(...)` writes semantic search results into a Snowflake table for later frame extraction and display.\n",
    "- `extract_and_upload_frames(...)` downloads the source video, extracts representative frames for selected segments, and uploads them to a Snowflake stage.\n",
    "- `orchestrate_video_search_and_frames(...)` ties together search, persistence, frame extraction, and LLM scoring into a single orchestration step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31310039-efa6-4b59-abd0-1eb1d28d64fb",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "UDTF_create_Video_Embed",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "TWELVE_LABS_API_KEY = \"YOUR_TWELVE_LABS_API_KEY\"  \n",
    "\n",
    "from snowflake.snowpark.functions import udtf, lit, Tuple\n",
    "from snowflake.snowpark.types import FloatType, StringType, StructType, StructField, Iterable, VectorType\n",
    "\n",
    "session.clear_imports()\n",
    "\n",
    "# Use parameterised package stage\n",
    "session.add_import(f'@{PKG_STAGE_FQN}/twelvelabs.zip')\n",
    "\n",
    "@udtf(\n",
    "    name=\"create_video_embeddings\",\n",
    "    packages=['httpx', 'pydantic'],\n",
    "    external_access_integrations=['twelvelabs_access_integration'],\n",
    "    secrets={'cred': 'twelve_labs_api'},\n",
    "    if_not_exists=True,\n",
    "    is_permanent=True,\n",
    "    # Use parameterised UDFs stage\n",
    "    stage_location=f'@{UDFS_STAGE_FQN}',\n",
    "    output_schema=StructType([\n",
    "        StructField(\"embedding\", VectorType(float, 1024)),\n",
    "        StructField(\"start_offset_sec\", FloatType()),\n",
    "        StructField(\"end_offset_sec\", FloatType()),\n",
    "        StructField(\"embedding_scope\", StringType())\n",
    "    ])\n",
    ")\n",
    "class create_video_embeddings:\n",
    "    def __init__(self):\n",
    "        from twelvelabs import TwelveLabs\n",
    "        from twelvelabs.models.embed import EmbeddingsTask\n",
    "        import _snowflake\n",
    "\n",
    "        twelve_labs_api_key = _snowflake.get_generic_secret_string('cred')\n",
    "        twelvelabs_client = TwelveLabs(api_key=twelve_labs_api_key)\n",
    "        self.twelvelabs_client = twelvelabs_client\n",
    "\n",
    "    def process(self, video_url: str) -> Iterable[Tuple[list, float, float, str]]:\n",
    "        task = self.twelvelabs_client.embed.task.create(\n",
    "            model_name=CHOSEN_MODEL,\n",
    "            video_url=video_url\n",
    "        )\n",
    "\n",
    "        status = task.wait_for_done(sleep_interval=60)\n",
    "\n",
    "        task = task.retrieve()\n",
    "        if task.video_embedding is not None and task.video_embedding.segments is not None:\n",
    "            for segment in task.video_embedding.segments:\n",
    "                yield (\n",
    "                    segment.embeddings_float,\n",
    "                    segment.start_offset_sec,\n",
    "                    segment.end_offset_sec,\n",
    "                    segment.embedding_scope,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f886ae-89af-4194-bd7b-3918888a6fbe",
   "metadata": {
    "language": "python",
    "name": "Def_txt_query_embed"
   },
   "outputs": [],
   "source": [
    "def create_and_store_text_query_embedding(text_query: str) -> int:\n",
    "    \"\"\"\n",
    "    Create a text embedding for `text_query`, store it in QUERY_EMBEDDINGS and return the generated QUERY_ID.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Call Twelve Labs Embed API in text mode\n",
    "    response = twelvelabs_client.embed.create(\n",
    "        model_name=CHOSEN_MODEL,\n",
    "        text=text_query,\n",
    "        text_truncate=\"start\"\n",
    "    )\n",
    "\n",
    "    if (\n",
    "        response.text_embedding is None\n",
    "        or response.text_embedding.segments is None\n",
    "        or len(response.text_embedding.segments) == 0\n",
    "    ):\n",
    "        raise ValueError(\"No text embedding returned from Twelve Labs for query: \" + text_query)\n",
    "\n",
    "    embedding_vector = response.text_embedding.segments[0].embeddings_float  # list[float]\n",
    "\n",
    "    # Build ARRAY literal for the vector\n",
    "    embedding_literal = \",\".join(str(x) for x in embedding_vector)\n",
    "\n",
    "    # Escape single quotes in the query text for SQL\n",
    "    escaped_text = text_query.replace(\"'\", \"''\")\n",
    "\n",
    "    # 2) Insert into the query-embeddings table\n",
    "    insert_sql = f\"\"\"\n",
    "        INSERT INTO {TEXT_QUERY_EMBEDDINGS_TABLE_FQN} (QUERY_TEXT, QUERY_EMBEDDING)\n",
    "        SELECT\n",
    "            '{escaped_text}' AS QUERY_TEXT,\n",
    "            ARRAY_CONSTRUCT({embedding_literal})::VECTOR(FLOAT, 1024) AS QUERY_EMBEDDING\n",
    "    \"\"\"\n",
    "    session.sql(insert_sql).collect()\n",
    "\n",
    "    # 3) Fetch the latest QUERY_ID for this text\n",
    "    select_sql = f\"\"\"\n",
    "        SELECT QUERY_ID\n",
    "        FROM {TEXT_QUERY_EMBEDDINGS_TABLE_FQN}\n",
    "        WHERE QUERY_TEXT = '{escaped_text}'\n",
    "        ORDER BY CREATED_AT DESC\n",
    "        LIMIT 1\n",
    "    \"\"\"\n",
    "    result_df = session.sql(select_sql).to_pandas()\n",
    "\n",
    "    return int(result_df[\"QUERY_ID\"].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e637faa-364e-4ea7-a1e4-bc3ff096bf9d",
   "metadata": {
    "language": "python",
    "name": "def_zero_shot_class"
   },
   "outputs": [],
   "source": [
    "def zero_shot_classify_sql(query_text: str, categories: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Uses Snowflake AISQL AI_CLASSIFY via SQL and returns the top label\n",
    "    (CATEGORY_ZERO_SHOT) for the given query_text and categories.\n",
    "    \"\"\"\n",
    "    if query_text is None or str(query_text).strip() == \"\":\n",
    "        return None\n",
    "\n",
    "    # Build the categories array literal: ['a','b',...]\n",
    "    cats_escaped = [c.replace(\"'\", \"''\") for c in categories]\n",
    "    cats_sql = \", \".join(f\"'{c}'\" for c in cats_escaped)\n",
    "    cats_array_literal = f\"[{cats_sql}]\"\n",
    "\n",
    "    # Escape the input text for SQL\n",
    "    q_escaped = query_text.replace(\"'\", \"''\")\n",
    "\n",
    "    # SQL: AI_CLASSIFY(...):labels[0] as CATEGORY_ZERO_SHOT\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "            AI_CLASSIFY('{q_escaped}', {cats_array_literal}):labels[0] AS CATEGORY_ZERO_SHOT\n",
    "    \"\"\"\n",
    "\n",
    "    df = session.sql(sql)\n",
    "    rows = df.collect()\n",
    "    if not rows:\n",
    "        return None\n",
    "\n",
    "    # Row field name is CATEGORY_ZERO_SHOT\n",
    "    return rows[0][\"CATEGORY_ZERO_SHOT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199b720-ec64-4571-b8ec-8ff5dc4704fe",
   "metadata": {
    "language": "python",
    "name": "Def_semantic_search"
   },
   "outputs": [],
   "source": [
    "def semantic_search(questions: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Create query embedding if it doesn't exist,\n",
    "    execute semantic search over video segments,\n",
    "    and return results.\n",
    "    \"\"\"\n",
    "\n",
    "    for q in questions:\n",
    "        # Normalize and escape input query for SQL safety\n",
    "        q_norm = q.lower()\n",
    "        q_norm_escaped = q_norm.replace(\"'\", \"''\")\n",
    "\n",
    "        # Check if an existing embedding for the query already exists in the database\n",
    "        existing_sql = f\"\"\"\n",
    "        SELECT QUERY_ID, CATEGORY_ZERO_SHOT\n",
    "        FROM {TEXT_QUERY_EMBEDDINGS_TABLE_FQN}\n",
    "        WHERE LOWER(QUERY_TEXT) = '{q_norm_escaped}'\n",
    "        ORDER BY CREATED_AT DESC\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "        existing_df = session.sql(existing_sql).to_pandas()\n",
    "\n",
    "        if not existing_df.empty:\n",
    "            # Use the most recent embedding and classification if found\n",
    "            query_id = int(existing_df[\"QUERY_ID\"].iloc[0])\n",
    "            category_zero_shot = existing_df[\"CATEGORY_ZERO_SHOT\"].iloc[0]\n",
    "        else:\n",
    "            # Create new query embedding if one doesn't exist\n",
    "            query_id = create_and_store_text_query_embedding(q)\n",
    "\n",
    "            # Perform zero-shot classification on the query text\n",
    "            category_zero_shot = zero_shot_classify_sql(q, ZERO_SHOT_CATEGORIES)\n",
    "\n",
    "            if category_zero_shot is not None:\n",
    "                # Update embedding table to include the zero-shot category\n",
    "                cat_escaped_for_update = category_zero_shot.replace(\"'\", \"''\")\n",
    "                update_sql = f\"\"\"\n",
    "                UPDATE {TEXT_QUERY_EMBEDDINGS_TABLE_FQN}\n",
    "                SET CATEGORY_ZERO_SHOT = '{cat_escaped_for_update}'\n",
    "                WHERE QUERY_ID = {query_id}\n",
    "                \"\"\"\n",
    "                session.sql(update_sql).collect()\n",
    "\n",
    "        # Build semantic similarity search query between query embedding and video segments\n",
    "        sql = f\"\"\"\n",
    "        WITH selected_query AS (\n",
    "            SELECT QUERY_EMBEDDING\n",
    "            FROM {TEXT_QUERY_EMBEDDINGS_TABLE_FQN}\n",
    "            WHERE QUERY_ID = {query_id}\n",
    "        ),\n",
    "        base_sim AS (\n",
    "            SELECT\n",
    "                v.URL              AS VIDEO_URL,\n",
    "                v.START_OFFSET_SEC AS START_OFFSET_SEC,\n",
    "                v.END_OFFSET_SEC   AS END_OFFSET_SEC,\n",
    "                v.EMBEDDING        AS VIDEO_EMBEDDING,\n",
    "                ROUND(\n",
    "                    VECTOR_COSINE_SIMILARITY(\n",
    "                        v.EMBEDDING::VECTOR(FLOAT, 1024),\n",
    "                        q.QUERY_EMBEDDING::VECTOR(FLOAT, 1024)\n",
    "                    ),\n",
    "                    4\n",
    "                ) AS SIMILARITY_SCORE\n",
    "            FROM {VIDEO_SEGMENT_EMBEDDINGS_TABLE_FQN} v\n",
    "            CROSS JOIN selected_query q\n",
    "        )\n",
    "        SELECT\n",
    "            VIDEO_URL,\n",
    "            START_OFFSET_SEC,\n",
    "            END_OFFSET_SEC,\n",
    "            SIMILARITY_SCORE,\n",
    "            0.0              AS LLM_SCORE,\n",
    "            SIMILARITY_SCORE AS FINAL_SCORE\n",
    "        FROM base_sim\n",
    "        ORDER BY FINAL_SCORE DESC\n",
    "        \"\"\"\n",
    "        # Execute SQL search and fetch results into a dataframe\n",
    "        full_df = session.sql(sql).to_pandas()\n",
    "\n",
    "        # Sort results by final semantic similarity score in descending order\n",
    "        result_df = full_df.sort_values(by=\"FINAL_SCORE\", ascending=False).copy()\n",
    "\n",
    "        # Return structured search results for the query\n",
    "        return {\n",
    "            \"query_id\": query_id,\n",
    "            \"query_text\": q,\n",
    "            \"category_zero_shot\": category_zero_shot,\n",
    "            \"results_df\": result_df,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb77fdf-7766-435c-8926-3061860d4ec6",
   "metadata": {
    "language": "python",
    "name": "llm_scoring_to_frames"
   },
   "outputs": [],
   "source": [
    "def apply_llm_scoring_to_frames(\n",
    "    query_id: int,\n",
    "    user_query: str,\n",
    "    video_frame_results_fqn: str,\n",
    "    frames_stage_name: str,\n",
    "    db_name: str,\n",
    "    schema_name: str,\n",
    "    session,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    For a given QUERY_ID, call Snowflake Cortex on each frame in VIDEO_FRAME_RESULTS\n",
    "    and update LLM_SCORE and FINAL_SCORE in-place.\n",
    "    \"\"\"\n",
    "    # Escape single quotes in user query\n",
    "    user_query_escaped = user_query.replace(\"'\", \"''\")\n",
    "    stage_string = f\"@{db_name}.{schema_name}.{frames_stage_name}\"\n",
    "\n",
    "    # 1) Compute LLM scores into a temporary table\n",
    "    sql_scored = f\"\"\"\n",
    "        CREATE OR REPLACE TEMP TABLE LLM_FRAME_SCORES AS\n",
    "        SELECT\n",
    "            v.RESULT_ID,\n",
    "            v.QUERY_ID,\n",
    "            v.FRAME_STAGE_PATH,\n",
    "            v.SIMILARITY_SCORE,\n",
    "            v.FINAL_SCORE,\n",
    "            SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                'claude-4-sonnet',\n",
    "                PROMPT(\n",
    "                    'You are a traffic analysis assistant. Answer based only on the provided image {{0}}. ' ||\n",
    "                    'The image provided is a screenshot of highway traffic footage. ' ||\n",
    "                    'Does the image provided contain: {user_query_escaped}? ' ||\n",
    "                    'Return a single decimal number between 0.0 (no confidence) and 1.0 (absolute confidence). ' ||\n",
    "                    'Provide only the decimal number, no other text.',\n",
    "                    TO_FILE('{stage_string}', v.FRAME_STAGE_PATH)\n",
    "                )\n",
    "            )::FLOAT AS LLM_RAW\n",
    "        FROM {video_frame_results_fqn} v\n",
    "        WHERE v.QUERY_ID = {query_id}\n",
    "          AND v.FRAME_STAGE_PATH IS NOT NULL\n",
    "    \"\"\"\n",
    "    session.sql(sql_scored).collect()\n",
    "\n",
    "    # 2) Update the main table from the temp table\n",
    "    sql_update = f\"\"\"\n",
    "        UPDATE {video_frame_results_fqn} t\n",
    "        SET\n",
    "            LLM_SCORE   = s.LLM_RAW,\n",
    "            FINAL_SCORE = t.SIMILARITY_SCORE * s.LLM_RAW\n",
    "        FROM LLM_FRAME_SCORES s\n",
    "        WHERE t.RESULT_ID = s.RESULT_ID\n",
    "          AND t.QUERY_ID  = {query_id}\n",
    "    \"\"\"\n",
    "    session.sql(sql_update).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dba9ae-4fc2-4408-9edb-2a99b505ca5c",
   "metadata": {
    "language": "python",
    "name": "Def_generate_video_embed"
   },
   "outputs": [],
   "source": [
    "def generate_video_embed(\n",
    "    video_url: str,\n",
    "    session,\n",
    "    video_segment_embeddings_fqn: str,\n",
    "    video_source_urls_table_fqn: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create embeddings for a single video URL and persist to VIDEO_SEGMENT_EMBEDDINGS.\n",
    "    Also marks the video as processed in VIDEO_SOURCE_URLS.\n",
    "    Skips work if embeddings already exist for this URL.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    escaped_url = video_url.replace(\"'\", \"''\")\n",
    "    existing_sql = f\"\"\"\n",
    "        SELECT COUNT(*) AS CNT\n",
    "        FROM {video_segment_embeddings_fqn}\n",
    "        WHERE URL = '{escaped_url}'\n",
    "    \"\"\"\n",
    "    existing_df = session.sql(existing_sql).to_pandas()\n",
    "    existing_cnt = int(existing_df[\"CNT\"].iloc[0]) if not existing_df.empty else 0\n",
    "\n",
    "    if existing_cnt > 0:\n",
    "        print(f\"Embeddings already exist for URL = {video_url}, skipping generation.\")\n",
    "        # ensure PROCESSED flag is true as well\n",
    "        update_sql = f\"\"\"\n",
    "            UPDATE {video_source_urls_table_fqn}\n",
    "            SET PROCESSED = TRUE,\n",
    "                PROCESSED_AT = COALESCE(PROCESSED_AT, CURRENT_TIMESTAMP())\n",
    "            WHERE URL = '{escaped_url}'\n",
    "        \"\"\"\n",
    "        session.sql(update_sql).collect()\n",
    "        return\n",
    "\n",
    "\n",
    "    # Build single-row dataframe for this URL\n",
    "    df = session.create_dataframe([[video_url]], schema=[\"url\"])\n",
    "\n",
    "    # Generate embeddings via UDTF\n",
    "    df_with_embeddings = df.join_table_function(\n",
    "        create_video_embeddings(df[\"url\"]).over(partition_by=\"url\")\n",
    "    )\n",
    "\n",
    "    # Persist into the fully-qualified VIDEO_SEGMENT_EMBEDDINGS table (append mode)\n",
    "    df_with_embeddings.write.mode(\"append\").save_as_table(\n",
    "        video_segment_embeddings_fqn\n",
    "    )\n",
    "\n",
    "    # Mark as processed in VIDEO_SOURCE_URLS\n",
    "    update_sql = f\"\"\"\n",
    "        UPDATE {video_source_urls_table_fqn}\n",
    "        SET PROCESSED = TRUE,\n",
    "            PROCESSED_AT = CURRENT_TIMESTAMP()\n",
    "        WHERE URL = '{escaped_url}'\n",
    "    \"\"\"\n",
    "    session.sql(update_sql).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e3dbc4-6c76-49bd-aed4-bf96cb247c1e",
   "metadata": {
    "language": "python",
    "name": "store_query_results"
   },
   "outputs": [],
   "source": [
    "def store_query_results_to_table(\n",
    "    query_result: dict,\n",
    "    video_url: str,\n",
    "    query_result_frames_fqn: str,\n",
    "    session,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Persist segments from a semantic search result into VIDEO_FRAME_RESULTS.\n",
    "    \"\"\"\n",
    "\n",
    "    query_id = int(query_result[\"query_id\"])\n",
    "    results_df = query_result[\"results_df\"]\n",
    "\n",
    "    if results_df.empty:\n",
    "        print(f\"No results for query ID {query_id}\")\n",
    "        return\n",
    "\n",
    "    existing_sql = f\"\"\"\n",
    "    SELECT COUNT(*) AS CNT\n",
    "    FROM {query_result_frames_fqn}\n",
    "    WHERE QUERY_ID = {query_id}\n",
    "    \"\"\"\n",
    "    existing_df = session.sql(existing_sql).to_pandas()\n",
    "    existing_cnt = int(existing_df[\"CNT\"].iloc[0]) if not existing_df.empty else 0\n",
    "    \n",
    "    if existing_cnt > 0:\n",
    "        print(\n",
    "            f\"Rows already exist in VIDEO_FRAME_RESULTS for QUERY_ID {query_id}, \"\n",
    "            \"skipping insert.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    values_clauses = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        qid = query_id\n",
    "        vurl = video_url.replace(\"'\", \"''\")\n",
    "        start_sec = float(row[\"START_OFFSET_SEC\"])\n",
    "        end_sec = float(row[\"END_OFFSET_SEC\"])\n",
    "        sim = float(row[\"SIMILARITY_SCORE\"])\n",
    "        llm_score = 0.0  # placeholder, will be updated by Cortex later\n",
    "        final_score = float(row[\"FINAL_SCORE\"])\n",
    "        frame_path = \"placeholder\"\n",
    "\n",
    "        values_clauses.append(\n",
    "            f\"({qid}, '{vurl}', {start_sec}, {end_sec}, {sim}, \"\n",
    "            f\"{llm_score}, '{frame_path}', {final_score})\"\n",
    "        )\n",
    "\n",
    "    if not values_clauses:\n",
    "        print(f\"No rows to insert for query ID {query_id}\")\n",
    "        return\n",
    "\n",
    "    values_sql = \",\".join(values_clauses)\n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO {query_result_frames_fqn}\n",
    "        (QUERY_ID, VIDEO_URL, START_OFFSET_SEC, END_OFFSET_SEC,\n",
    "         SIMILARITY_SCORE, LLM_SCORE, FRAME_STAGE_PATH, FINAL_SCORE)\n",
    "    VALUES {values_sql}\n",
    "    \"\"\"\n",
    "    session.sql(insert_sql).collect()\n",
    "    print(\n",
    "        f\"{len(values_clauses)} results stored in VIDEO_FRAME_RESULTS \"\n",
    "        f\"for Query ID {query_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97099425-2eb1-41cc-9691-bdebd20116a5",
   "metadata": {
    "language": "python",
    "name": "extract_and_upload_frame"
   },
   "outputs": [],
   "source": [
    "def extract_and_upload_frames(\n",
    "    video_url: str,\n",
    "    segments_df,\n",
    "    stage_name: str,\n",
    "    db_name: str,\n",
    "    schema_name: str,\n",
    "    query_result_frames_fqn: str,\n",
    "    query_id: int,\n",
    "    session,\n",
    ") -> dict:\n",
    "    frame_map = {}\n",
    "\n",
    "    # Guard: skip if frames already exist\n",
    "    existing_sql = f\"\"\"\n",
    "        SELECT COUNT(*) AS CNT\n",
    "        FROM {query_result_frames_fqn}\n",
    "        WHERE QUERY_ID = {query_id}\n",
    "          AND FRAME_STAGE_PATH IS NOT NULL\n",
    "          AND FRAME_STAGE_PATH <> ''\n",
    "          AND FRAME_STAGE_PATH <> 'placeholder'\n",
    "    \"\"\"\n",
    "    existing_df = session.sql(existing_sql).to_pandas()\n",
    "    existing_cnt = int(existing_df[\"CNT\"].iloc[0]) if not existing_df.empty else 0\n",
    "    if existing_cnt > 0:\n",
    "        print(f\"Frames already exist for QUERY_ID {query_id}, skipping extraction.\")\n",
    "        return frame_map\n",
    "\n",
    "    # Download the full video once to a temp file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as tmp:\n",
    "        response = requests.get(video_url, stream=True, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                tmp.write(chunk)\n",
    "        tmp_path = tmp.name\n",
    "\n",
    "    try:\n",
    "        clip = VideoFileClip(tmp_path)\n",
    "\n",
    "        for _, row in segments_df.iterrows():\n",
    "            start_offset = float(row[\"START_OFFSET_SEC\"])\n",
    "            end_offset = float(row[\"END_OFFSET_SEC\"])\n",
    "            result_id = int(row[\"RESULT_ID\"])\n",
    "            frame_timestamp = start_offset + (end_offset - start_offset) / 2.0\n",
    "\n",
    "            try:\n",
    "                frame_array = clip.get_frame(frame_timestamp)\n",
    "                img = PILImage.fromarray(frame_array.astype(\"uint8\"))\n",
    "\n",
    "                with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as img_tmp:\n",
    "                    img.save(img_tmp, format=\"JPEG\", quality=90)\n",
    "                    img_tmp_path = img_tmp.name\n",
    "\n",
    "                filename = f\"frame_{int(start_offset)}s.jpg\"\n",
    "\n",
    "                put_result = session.file.put(\n",
    "                    img_tmp_path,\n",
    "                    f\"@{db_name}.{schema_name}.{stage_name}\",\n",
    "                    overwrite=True,\n",
    "                    auto_compress=False\n",
    "                )\n",
    "                os.remove(img_tmp_path)\n",
    "\n",
    "                relative_path = put_result[0].target\n",
    "\n",
    "                update_sql = f\"\"\"\n",
    "                    UPDATE {query_result_frames_fqn}\n",
    "                    SET FRAME_STAGE_PATH = '{relative_path}'\n",
    "                    WHERE RESULT_ID = {result_id}\n",
    "                \"\"\"\n",
    "                session.sql(update_sql).collect()\n",
    "\n",
    "                frame_map[start_offset] = relative_path\n",
    "                print(f\"Uploaded frame at {start_offset}s to stage path {relative_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing frame at {start_offset}s: {e}\")\n",
    "\n",
    "    finally:\n",
    "        clip.close()\n",
    "        os.remove(tmp_path)\n",
    "\n",
    "    return frame_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65225d-5d22-4616-a159-f5b0cdc45685",
   "metadata": {
    "language": "python",
    "name": "orchestrator"
   },
   "outputs": [],
   "source": [
    "def orchestrate_video_search_and_frames(\n",
    "    question_text: str,\n",
    "    video_url: str,\n",
    "    query_result_frames_fqn: str,\n",
    "    db_name: str,\n",
    "    schema_name: str,\n",
    "    frames_stage_name: str,\n",
    "    session,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Orchestrate semantic search, result persistence, frame extraction, and LLM scoring\n",
    "    for a single question.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Run semantic query over video segments\n",
    "    result = semantic_search(\n",
    "        questions=[question_text],\n",
    "    )\n",
    "    if result is None or result[\"results_df\"].empty:\n",
    "        print(\"No segments returned from semantic_search.\")\n",
    "        return {\"queryresult\": result, \"framemap\": {}, \"segmentsdf\": None}\n",
    "\n",
    "    query_id = int(result[\"query_id\"])\n",
    "\n",
    "    # 2. Persist segments into VIDEO_FRAME_RESULTS if not already there\n",
    "    store_query_results_to_table(\n",
    "        query_result=result,\n",
    "        video_url=video_url,\n",
    "        query_result_frames_fqn=query_result_frames_fqn,\n",
    "        session=session,\n",
    "    )\n",
    "\n",
    "    # 3. Reload VIDEO_FRAME_RESULTS rows for this QUERY_ID to get RESULT_IDs\n",
    "    segments_df = (\n",
    "        session.table(query_result_frames_fqn)\n",
    "        .filter(f\"QUERY_ID = {query_id}\")\n",
    "        .to_pandas()\n",
    "    )\n",
    "\n",
    "    # 4. Extract and upload frames only if frames for this QUERY_ID do not already exist\n",
    "    frame_map = extract_and_upload_frames(\n",
    "        video_url=video_url,\n",
    "        segments_df=segments_df,\n",
    "        stage_name=frames_stage_name,\n",
    "        db_name=db_name,\n",
    "        schema_name=schema_name,\n",
    "        query_result_frames_fqn=query_result_frames_fqn,\n",
    "        query_id=query_id,\n",
    "        session=session,\n",
    "    )\n",
    "\n",
    "    # 5. Apply LLM scoring to frames for this query\n",
    "    apply_llm_scoring_to_frames(\n",
    "        query_id=query_id,\n",
    "        user_query=question_text,\n",
    "        video_frame_results_fqn=query_result_frames_fqn,\n",
    "        frames_stage_name=frames_stage_name,\n",
    "        db_name=db_name,\n",
    "        schema_name=schema_name,\n",
    "        session=session,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"query_result\": result,\n",
    "        \"frame_map\": frame_map,\n",
    "        \"segments_df\": segments_df,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f1c1a",
   "metadata": {},
   "source": [
    "## Streamlit application\n",
    "\n",
    "The following cell defines a simple Streamlit app that lets you interactively search across prepared highway videos.  \n",
    "It reads available video URLs from Snowflake, allows you to prepare a selected video by generating embeddings, and then runs semantic search to display the top‑matching frames for a natural‑language query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1cab1-1563-4c1b-95f7-ecc39e42268b",
   "metadata": {
    "language": "python",
    "name": "Streamlit_App"
   },
   "outputs": [],
   "source": [
    "# Read all videos, their processed status, and titles\n",
    "video_urls_df = session.sql(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        URL,\n",
    "        TITLE,\n",
    "        PROCESSED\n",
    "    FROM {VIDEO_SOURCE_URLS_TABLE_FQN}\n",
    "    \"\"\"\n",
    ").to_pandas()\n",
    "\n",
    "# Handle case where there are no videos configured\n",
    "if video_urls_df.empty:\n",
    "    st.warning(\"No video URLs found in VIDEO_SOURCE_URLS.\")\n",
    "    selected_url = None\n",
    "\n",
    "else:\n",
    "    # Build labels with ✅ / ❌ and human-readable title\n",
    "    def make_label(row):\n",
    "        status_icon = \"✅\" if bool(row.get(\"PROCESSED\", False)) else \"❌\"\n",
    "        title = row.get(\"TITLE\") or row[\"URL\"]\n",
    "        return f\"{status_icon} {title}\"\n",
    "\n",
    "    # Build dropdown options\n",
    "    options = video_urls_df.apply(make_label, axis=1).tolist()\n",
    "\n",
    "    # Map label back to URL\n",
    "    label_to_url = {\n",
    "        options[i]: video_urls_df[\"URL\"].iloc[i]\n",
    "        for i in range(len(options))\n",
    "    }\n",
    "\n",
    "    selected_label = st.selectbox(\n",
    "        \"Choose a video to search in:\",\n",
    "        options=options,\n",
    "    )\n",
    "    selected_url = label_to_url[selected_label]\n",
    "\n",
    "# App title and query input\n",
    "st.title(\"Highway video search\")\n",
    "\n",
    "user_query = st.text_input(\n",
    "    \"Describe the vehicle or scene you are looking for:\",\n",
    "    value=\"Medium rigid flatbed tipper truck carrying sand\",\n",
    ")\n",
    "\n",
    "# Guard when no videos are available\n",
    "if selected_url is None:\n",
    "    st.info(\"Add at least one video URL to VIDEO_SOURCE_URLS to begin.\")\n",
    "\n",
    "else:\n",
    "    # Look up processed flag\n",
    "    selected_row = video_urls_df[\n",
    "        video_urls_df[\"URL\"] == selected_url\n",
    "    ].iloc[0]\n",
    "\n",
    "    is_processed = bool(selected_row.get(\"PROCESSED\", False))\n",
    "\n",
    "    if not is_processed:\n",
    "        st.warning(\"This video has not been prepared yet.\")\n",
    "    else:\n",
    "        st.success(\"This video is prepared and ready for search.\")\n",
    "\n",
    "    # Prepare video button\n",
    "    if not is_processed and st.button(\"Prepare selected video\"):\n",
    "        st.write(\"Preparing video (creating embeddings)…\")\n",
    "\n",
    "        generate_video_embed(\n",
    "            video_url=selected_url,\n",
    "            session=session,\n",
    "            video_segment_embeddings_fqn=VIDEO_SEGMENT_EMBEDDINGS_TABLE_FQN,\n",
    "            video_source_urls_table_fqn=VIDEO_SOURCE_URLS_TABLE_FQN,\n",
    "        )\n",
    "\n",
    "        st.success(\"Video preparation completed. Refresh the page to update status.\")\n",
    "\n",
    "    # Search logic\n",
    "    if is_processed and st.button(\"Search video segments\") and user_query.strip():\n",
    "        st.write(\"Running semantic search…\")\n",
    "\n",
    "        orchestration = orchestrate_video_search_and_frames(\n",
    "            question_text=user_query,\n",
    "            video_url=selected_url,\n",
    "            query_result_frames_fqn=VIDEO_FRAME_RESULTS_TABLE_FQN,\n",
    "            db_name=DB_NAME,\n",
    "            schema_name=SCHEMA_NAME,\n",
    "            frames_stage_name=VIDEO_FRAME_STAGE_NAME,\n",
    "            session=session,\n",
    "        )\n",
    "\n",
    "        result = orchestration.get(\"query_result\")\n",
    "\n",
    "        if result is None or result[\"results_df\"].empty:\n",
    "            st.info(\"No segments found for this query.\")\n",
    "\n",
    "        else:\n",
    "            query_id = int(result[\"query_id\"])\n",
    "\n",
    "            frames_df = (\n",
    "                session.table(VIDEO_FRAME_RESULTS_TABLE_FQN)\n",
    "                .filter(f\"QUERY_ID = {query_id}\")\n",
    "                .to_pandas()\n",
    "            )\n",
    "\n",
    "            if frames_df.empty:\n",
    "                st.info(\"No frame results found in VIDEO_FRAME_RESULTS for this query.\")\n",
    "\n",
    "            else:\n",
    "                frames_df = (\n",
    "                    frames_df\n",
    "                    .sort_values(by=\"FINAL_SCORE\", ascending=False)\n",
    "                    .head(6)\n",
    "                )\n",
    "\n",
    "                st.subheader(\"Top matching frames\")\n",
    "\n",
    "                num_cols = 2\n",
    "                num_rows = 3\n",
    "\n",
    "                for row_idx in range(num_rows):\n",
    "                    cols = st.columns(num_cols)\n",
    "\n",
    "                    for col_idx in range(num_cols):\n",
    "                        idx = row_idx * num_cols + col_idx\n",
    "                        if idx >= len(frames_df):\n",
    "                            break\n",
    "\n",
    "                        row = frames_df.iloc[idx]\n",
    "\n",
    "                        frame_path = row[\"FRAME_STAGE_PATH\"]\n",
    "                        start_offset = row[\"START_OFFSET_SEC\"]\n",
    "                        end_offset = row[\"END_OFFSET_SEC\"]\n",
    "\n",
    "                        full_stage_path = f\"@{DB_NAME}.{SCHEMA_NAME}.{VIDEO_FRAME_STAGE_NAME}/{frame_path}\"\n",
    "                        \n",
    "                        get_res = session.file.get(\n",
    "                            full_stage_path,    \n",
    "                            \"/tmp\"             # local directory in the container\n",
    "                        )\n",
    "                        \n",
    "                        local_filename = get_res[0].file\n",
    "                        local_filepath = f\"/tmp/{local_filename}\"\n",
    "                        \n",
    "                        with cols[col_idx]:\n",
    "                            st.image(\n",
    "                                local_filepath,\n",
    "                                caption=f\"Segment {start_offset:.1f}s–{end_offset:.1f}s\",\n",
    "                                use_column_width=True,\n",
    "                            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2055c-0962-4d5f-bfab-4fd18c270e40",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": [
    "## Testing and diagnostics\n",
    "\n",
    "The next cells provide two high‑level tests to validate the pipeline.  \n",
    "The first test re‑scores existing video segments for a fixed query using only stored embeddings, and the second test inspects existing frame‑level scores for the same query to help you verify that frame extraction and LLM scoring behaved as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d7d8a-de52-45af-b60c-3da75f415fcf",
   "metadata": {
    "language": "python",
    "name": "Save_Video_Embeddings"
   },
   "outputs": [],
   "source": [
    "# One-off batch job to generate video segment embeddings\n",
    "\n",
    "# Build a dataframe of video URLs to process\n",
    "df = session.create_dataframe(video_urls, schema=['url'])\n",
    "\n",
    "# Invoke the UDTF to create embeddings for each URL (one row per segment)\n",
    "df = df.join_table_function(\n",
    "    create_video_embeddings(df['url']).over(partition_by=\"url\")\n",
    ")\n",
    "\n",
    "# Persist all generated segment embeddings into the target table\n",
    "df.write.mode('overwrite').save_as_table(\n",
    "    VIDEO_SEGMENT_EMBEDDINGS_TABLE_FQN\n",
    ")\n",
    "\n",
    "# Read back the persisted embeddings for inspection\n",
    "df = session.table(VIDEO_SEGMENT_EMBEDDINGS_TABLE_FQN)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f57847-877c-4b87-8b69-f626bc10489c",
   "metadata": {
    "language": "python",
    "name": "test_query_vs_segments"
   },
   "outputs": [],
   "source": [
    "# ---- TEST 1: Re-score existing video segments for a fixed query (no new embeddings) ----\n",
    "# This cell:\n",
    "#   * Uses the existing hardcoded question text\n",
    "#   * Reuses an existing QUERY_ID + embedding from TEXT_QUERY_EMBEDDINGS_TABLE_FQN\n",
    "#   * Runs cosine similarity against VIDEO_SEGMENT_EMBEDDINGS_TABLE_FQN\n",
    "#   * DOES NOT call Twelve Labs or create any new embeddings\n",
    "\n",
    "test_query = \"Medium rigid flatbed tipper truck carrying sand\"\n",
    "\n",
    "# Normalise and escape for lookup\n",
    "q_norm = test_query.lower()\n",
    "q_norm_escaped = q_norm.replace(\"'\", \"''\")\n",
    "\n",
    "# 1. Look up an existing QUERY_ID ONLY – do not generate a new one\n",
    "existing_sql = f\"\"\"\n",
    "SELECT QUERY_ID\n",
    "FROM {TEXT_QUERY_EMBEDDINGS_TABLE_FQN}\n",
    "WHERE LOWER(QUERY_TEXT) = '{q_norm_escaped}'\n",
    "ORDER BY CREATED_AT DESC\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "existing_df = session.sql(existing_sql).to_pandas()\n",
    "\n",
    "if existing_df.empty:\n",
    "    raise RuntimeError(\n",
    "        \"No existing embedding found for the test query. \"\n",
    "        \"Run the regular flow once to create the text embedding, \"\n",
    "        \"then re-run this cell.\"\n",
    "    )\n",
    "\n",
    "query_id = int(existing_df[\"QUERY_ID\"].iloc[0])\n",
    "print(f\"Using existing QUERY_ID = {query_id} for test query.\")\n",
    "\n",
    "# 2. Pure SQL semantic similarity against preexisting video segment embeddings\n",
    "sql_test_segments = f\"\"\"\n",
    "WITH selected_query AS (\n",
    "    SELECT QUERY_EMBEDDING\n",
    "    FROM {TEXT_QUERY_EMBEDDINGS_TABLE_FQN}\n",
    "    WHERE QUERY_ID = {query_id}\n",
    "),\n",
    "base_sim AS (\n",
    "    SELECT\n",
    "        v.URL                 AS VIDEO_URL,\n",
    "        v.START_OFFSET_SEC    AS START_OFFSET_SEC,\n",
    "        v.END_OFFSET_SEC      AS END_OFFSET_SEC,\n",
    "        v.EMBEDDING           AS VIDEO_EMBEDDING,\n",
    "        ROUND(\n",
    "            VECTOR_COSINE_SIMILARITY(\n",
    "                v.EMBEDDING::VECTOR(FLOAT, 1024),\n",
    "                q.QUERY_EMBEDDING::VECTOR(FLOAT, 1024)\n",
    "            ),\n",
    "            4\n",
    "        ) AS SIMILARITY_SCORE,\n",
    "        q.QUERY_EMBEDDING     AS QUERY_EMBEDDING\n",
    "    FROM {VIDEO_SEGMENT_EMBEDDINGS_TABLE_FQN} v\n",
    "    CROSS JOIN selected_query q\n",
    ")\n",
    "SELECT\n",
    "    VIDEO_URL,\n",
    "    START_OFFSET_SEC,\n",
    "    END_OFFSET_SEC,\n",
    "    SIMILARITY_SCORE,\n",
    "    QUERY_EMBEDDING\n",
    "FROM base_sim\n",
    "ORDER BY SIMILARITY_SCORE DESC\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "test_segments_df = session.sql(sql_test_segments).to_pandas()\n",
    "\n",
    "# Optionally restrict to top N for inspection\n",
    "top10_segments_df = test_segments_df.head(10).copy()\n",
    "\n",
    "print(\"Top 10 segment matches for the fixed test query:\")\n",
    "top10_segments_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdbf6c4-869c-4750-a1a7-c40737a56a34",
   "metadata": {
    "language": "python",
    "name": "Test_query_frames_scores"
   },
   "outputs": [],
   "source": [
    "# ---- TEST 2: Inspect existing frame-level scores for the same fixed query ----\n",
    "# This cell:\n",
    "#   * Uses the same hardcoded test_query\n",
    "#   * Finds its existing QUERY_ID\n",
    "#   * Reads all rows from VIDEO_FRAME_RESULTS_TABLE_FQN for that QUERY_ID\n",
    "#   * DOES NOT:\n",
    "#       - extract new frames\n",
    "#       - call Snowflake Cortex\n",
    "#       - modify any tables\n",
    "\n",
    "test_query = \"Medium rigid flatbed tipper truck carrying sand\"\n",
    "\n",
    "# Normalise and escape for lookup\n",
    "q_norm = test_query.lower()\n",
    "q_norm_escaped = q_norm.replace(\"'\", \"''\")\n",
    "\n",
    "# 1. Look up existing QUERY_ID only\n",
    "existing_sql = f\"\"\"\n",
    "SELECT QUERY_ID\n",
    "FROM {TEXT_QUERY_EMBEDDINGS_TABLE_FQN}\n",
    "WHERE LOWER(QUERY_TEXT) = '{q_norm_escaped}'\n",
    "ORDER BY CREATED_AT DESC\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "existing_df = session.sql(existing_sql).to_pandas()\n",
    "\n",
    "if existing_df.empty:\n",
    "    raise RuntimeError(\n",
    "        \"No existing embedding / QUERY_ID found for the test query. \"\n",
    "        \"Run the main orchestration once to seed QUERY_ID + frames, \"\n",
    "        \"then re-run this cell.\"\n",
    "    )\n",
    "\n",
    "query_id = int(existing_df[\"QUERY_ID\"].iloc[0])\n",
    "print(f\"Using existing QUERY_ID = {query_id} for frame-level test.\")\n",
    "\n",
    "# 2. Read existing frame results for this QUERY_ID\n",
    "frames_sql = f\"\"\"\n",
    "SELECT\n",
    "    RESULT_ID,\n",
    "    VIDEO_URL,\n",
    "    START_OFFSET_SEC,\n",
    "    END_OFFSET_SEC,\n",
    "    SIMILARITY_SCORE,\n",
    "    LLM_SCORE,\n",
    "    FINAL_SCORE\n",
    "FROM {VIDEO_FRAME_RESULTS_TABLE_FQN}\n",
    "WHERE QUERY_ID = {query_id}\n",
    "ORDER BY FINAL_SCORE DESC\n",
    "\"\"\"\n",
    "frames_df = session.sql(frames_sql).to_pandas()\n",
    "\n",
    "if frames_df.empty:\n",
    "    raise RuntimeError(\n",
    "        \"No rows found in VIDEO_FRAME_RESULTS for this QUERY_ID. \"\n",
    "        \"Run the orchestration once to persist frames + scores, \"\n",
    "        \"then re-run this cell.\"\n",
    "    )\n",
    "\n",
    "# Optional: restrict to top N for quick inspection\n",
    "top10_frames_df = frames_df.head(10).copy()\n",
    "\n",
    "print(\"Top 10 frame-level results for the fixed test query:\")\n",
    "top10_frames_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051c613-28c9-4a16-91eb-5da2156d2f35",
   "metadata": {
    "language": "python",
    "name": "Reset_vid_img_embed"
   },
   "outputs": [],
   "source": [
    "# --- Reset video embeddings and frame images (does NOT touch text query embeddings) ---\n",
    "\n",
    "# 1) Delete all files from the video frame stage\n",
    "#    This removes the JPEG files previously extracted for frames.\n",
    "session.sql(\n",
    "    f\"REMOVE @{DB_NAME}.{SCHEMA_NAME}.{VIDEO_FRAME_STAGE_NAME}\"\n",
    ").collect()\n",
    "\n",
    "# 2) Truncate the VIDEO_FRAME_RESULTS table\n",
    "#    This removes frame-level results, including FRAME_STAGE_PATH and scores.\n",
    "session.sql(f\"TRUNCATE TABLE {VIDEO_FRAME_RESULTS_TABLE_FQN}\").collect()\n",
    "\n",
    "# 3) Truncate the VIDEO_SEGMENT_EMBEDDINGS table using the base name\n",
    "#    Use the original base table name with DB/SCHEMA instead of the mis-assigned FQN variable.\n",
    "session.sql(\n",
    "    f\"TRUNCATE TABLE {DB_NAME}.{SCHEMA_NAME}.VIDEO_SEGMENT_EMBEDDINGS\"\n",
    ").collect()\n",
    "\n",
    "# 4) Reset the PROCESSED flag on all videos\n",
    "#    This ensures the app knows they need to be prepared again.\n",
    "session.sql(\n",
    "    f\"UPDATE {VIDEO_SOURCE_URLS_TABLE_FQN} \"\n",
    "    f\"SET PROCESSED = FALSE, PROCESSED_AT = NULL\"\n",
    ").collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "roger@email.com",
   "authorId": "493017061839",
   "authorName": "Roger",
   "lastEditTime": 1769126380063,
   "notebookId": "agdilo6fmzfh4bs5jcto",
   "sessionId": "f48de030-1ac5-4030-8ab5-078b8ccf389c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
